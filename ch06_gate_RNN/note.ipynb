{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4c05e0",
   "metadata": {},
   "source": [
    "# Chapter 6. RNN with Gate (LSTM, GRU 계층)\n",
    "\n",
    "## 1. RNN의 문제점\n",
    "\n",
    "앞 장에서 언급한 대로, RNN은 시퀀스가 길어질 경우, gradient vanishing (or gradient exploding) 문제가 발생한다.\n",
    "\n",
    "- 원인 1 : RNN에서 계산되는 함수 $\\tanh(x)$의 형태를 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02270285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tanh function illustration\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(-5,5,0.1)\n",
    "y1 = np.tanh(x)\n",
    "y2 = 1 - y1 ** 2\n",
    "plt.plot(x,y1,label='y=tanh(x)')\n",
    "plt.plot(x,y2,ls='--',label='dy/dx')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32915c",
   "metadata": {},
   "source": [
    "    위와 같이, $\\tanh(x)$는 0에서는 기울기가 1이지만, 0에서 멀어질수록 기울기가 0에 가까워지는 문제가 있다.\n",
    "    -> 기울기가 역전파를 반복할수록 작아지는 문제 발생.\n",
    "    NOTE : 이 문제의 경우 ReLU 함수를 써서 대체 가능.\n",
    "- 원인 2 : RNN 계층의 시간에 따른 기울기 역전파에는 weight matrix $W_h$가 연속해서 곱해짐.<br>\n",
    "    -> 시간축으로의 역전파가 반복될 수록 $W^2_h$, $W^3_h$, ... 식으로 연속해서 곱해지면, 0으로 수렴하거나, 무한대로 발산할 수 있음. \n",
    "    <br>\n",
    "    https://arxiv.org/abs/1211.5063 참고\n",
    "    \n",
    "\n",
    "- Gradient exploding 문제 대책 : gradient clipping.\n",
    "    - Gradient의 L2 norm이 *threshold*보다 커질 경우, gradient $g$를 다음과 같이 rescaling함.<br>\n",
    "\\begin{equation}\n",
    "g_{new} = \\frac{\\textit{threshold}}{||g||}g .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c721c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[3.37731592, 8.11998845, 7.96032326],\n",
      "       [0.87341069, 9.56385317, 9.25867808],\n",
      "       [6.48460757, 2.49734401, 5.56587231]]), array([[8.67305792, 8.93943951, 6.46754862],\n",
      "       [1.76190047, 6.83608366, 8.01913903],\n",
      "       [3.58488989, 7.74981107, 4.05756025]])]\n",
      "[array([[0.5976254 , 1.43685443, 1.40860123],\n",
      "       [0.15455244, 1.69235029, 1.63834871],\n",
      "       [1.14746926, 0.44191193, 0.98489651]]), array([[1.5347216 , 1.58185856, 1.14445063],\n",
      "       [0.31177316, 1.20966392, 1.41900885],\n",
      "       [0.63435619, 1.37135052, 0.71799652]])]\n"
     ]
    }
   ],
   "source": [
    "# Gradient clipping\n",
    "# common/util.py 에 구현됨.\n",
    "\n",
    "dW1 = np.random.rand(3,3) * 10\n",
    "dW2 = np.random.rand(3,3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0 # threshold\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm) # L2 norm\n",
    "    \n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "          \n",
    "print(grads)\n",
    "clip_grads(grads,max_norm)\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541d834",
   "metadata": {},
   "source": [
    "## 2. Gradient Vanishing and LSTM\n",
    "\n",
    "- Memory cell $c_t$ : 계층 내에서만 전파되는 추가 요소. 은닉상태 (hidden state)와는 다름.\n",
    "    - 과거로부터 시간 $t$ 까지의 정보가 저장되어 있음.\n",
    "    - $h_{t-1}$, $c_{t-1}$, $x_t$를 가지고 $c_t$가 결정됨.\n",
    "    - 갱신된 $c_t$를 가지고 $h_t$가 계산됨. <br>\n",
    "    $h_t = \\tanh(c_t)$. \n",
    "- Gate : 이전 계층에서 다음 계층으로 얼만큼 정보를 보낼 것이냐? -> 열림 상태.\n",
    "    - value = 0 ~ 1 : 0일 때, 완전 차단. 1일 때 완전 전달.\n",
    "    - 열림 상태도 학습으로 조절될 예정.\n",
    "- Output Gate : $\\tanh(c_t)$ 에 대해 게이트를 적용.\n",
    "    - 열림 상태는 $o=\\sigma(x_t W^{(o)}_x h_{t-1} W^{(o)}_h + b^{(o)})$, sigmoid 함수로 결정됨.\n",
    "    - $o$가 결정되면, $h_t = o \\odot \\tanh(c_t) $. ($\\odot$ : 원소별 곱.)\n",
    "- Forget Gate : $c_{t-1}$ 의 일부를 버리는 게이트.\n",
    "    - 게이트 열림 $f=\\sigma(x_t W^{(f)}_x h_{t-1} W^{(f)}_h + b^{(f)})$ 에 대해\n",
    "    - $c_t = f \\odot c_{t-1}$ 로 순전파됨.\n",
    "- 새로운 기억 요소 g 생성\n",
    "    - $g = \\tanh(x_t W^{(g)}_x h_{t-1} W^{(g)}_h + b^{(g)})$ 생성.\n",
    "    - $g$ 만 $\\tanh$ 함수임에 유의.\n",
    "- Input gate : 기억 요소 g에 대한 gate\n",
    "    - $i = \\sigma(x_t W^{(i)}_x h_{t-1} W^{(i)}_h + b^{(i)})$. \n",
    "    \n",
    "- 최종 기억안\n",
    "    - $c_t = f \\odot c_{t-1} + g \\odot i$ : 현재 시간대의 기억셀은 이전 기억 셀의 일부와 현재 시간 대의 정보 일부를 같이 저장함.\n",
    "    - $h_t = o \\odot \\tanh(c_t)$ : 갱신된 기억셀을 게이트에 통과시켜 새로운 은닉상태 생성.\n",
    "- $x_t W_x h_{t-1} W_h + b $ 의 형태가 반복되기 때문에 (affine transformation), 각 weight 및 bias를 하나로 합쳐서 계산.\n",
    "    - 큰 행렬의 연산이 작은 행렬을 여러번 연산하는 것보다 빠르기 때문.\n",
    "\n",
    "\\begin{equation}\n",
    "x_t \\times [ W^{(f)}_x W^{(g)}_x W^{(i)}_x W^{(o)}_x ] + h_{t-1} \\times [ W^{(f)}_h W^{(g)}_h W^{(i)}_h W^{(o)}_h ]\n",
    "+ [ b^{(f)} b^{(g)} b^{(i)} b^{(o)} ] . \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2efcf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSTM 계층\n",
    "# class LSTM:\n",
    "#     def __init__(self, Wx, Wh, b):\n",
    "#         self.params = [Wx, Wh, b]\n",
    "#         self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "#         self.cache = None\n",
    "    \n",
    "#     # forward propagation : Input (x), memory cell (c_prev) 와 hidden state (h_prev) 가 인자로 전달됨.\n",
    "#     def forward(self, x, h_prev, c_prev):\n",
    "#         '''\n",
    "#         parameters\n",
    "#         N : number of samples in the mini-batch\n",
    "#         H : number of hidden nodes\n",
    "#         '''\n",
    "#         Wx, Wh, b = self.params\n",
    "#         N, H = h_prev.shape\n",
    "        \n",
    "#         # Affine transformation (= affine layer 와 똑같은 순전파 연산 시행함.)\n",
    "#         A = np.matmul(x,Wx) + np.matmul(h_prev,Wh) + b\n",
    "        \n",
    "#         # stack의 순서는 f,g,i,o. (note의 수식과 같음.)\n",
    "#         f = A[:, :H]\n",
    "#         g = A[:, H:2*H]\n",
    "#         i = A[:, 2*H:3*H]\n",
    "#         o = A[:, 3*H:]\n",
    "        \n",
    "#         f = sigmoid(f)\n",
    "#         g = np.tanh(g)\n",
    "#         i = sigmoid(i)\n",
    "#         o = sigmoid(o)\n",
    "        \n",
    "#         # Element-wise multiplication and additions\n",
    "#         c_next = f * c_prev + g*i\n",
    "#         h_next = o * np.tanh(c_next)\n",
    "        \n",
    "#         self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "#         return h_next, c_next\n",
    "    \n",
    "#     def backward(self, dh_next, dc_next):\n",
    "#         Wx, Wh, b = self.params\n",
    "#         x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "#         tanh_c_next = np.tanh(c_next)\n",
    "        \n",
    "#         # ds : dc_next 와 dh_t에서 온 역전파 값을 더함.\n",
    "#         # h_t = o * tanh(c_next) 이므로, \n",
    "#         # ds = dc_next + dh_next * dh_next/dtanh(c_next) * dtanh(c_next)/dc_next\n",
    "#         # ds = dc_next + dh_next * o * (1- tanh**2). \n",
    "#         ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "#         dc_prev = ds * f\n",
    "\n",
    "#         di = ds * g\n",
    "#         df = ds * c_prev\n",
    "#         do = dh_next * tanh_c_next\n",
    "#         dg = ds * i\n",
    "\n",
    "#         di *= i * (1 - i)\n",
    "#         df *= f * (1 - f)\n",
    "#         do *= o * (1 - o)\n",
    "#         dg *= (1 - g ** 2)\n",
    "\n",
    "#         # 각 게이트 및 출력에 대한 slice node를 역전파에서 옆으로 쌓기.\n",
    "#         dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "#         dWh = np.dot(h_prev.T, dA)\n",
    "#         dWx = np.dot(x.T, dA)\n",
    "#         db = dA.sum(axis=0)\n",
    "\n",
    "#         self.grads[0][...] = dWx\n",
    "#         self.grads[1][...] = dWh\n",
    "#         self.grads[2][...] = db\n",
    "\n",
    "#         dx = np.dot(dA, Wx.T)\n",
    "#         dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "#         return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6151b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 9999.69\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 2920.48\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 7[s] | 퍼플렉서티 1242.32\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 10[s] | 퍼플렉서티 961.20\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 14[s] | 퍼플렉서티 788.90\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 17[s] | 퍼플렉서티 666.32\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 21[s] | 퍼플렉서티 642.06\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 25[s] | 퍼플렉서티 611.99\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 29[s] | 퍼플렉서티 575.17\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 33[s] | 퍼플렉서티 587.11\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 36[s] | 퍼플렉서티 499.93\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 40[s] | 퍼플렉서티 500.91\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 44[s] | 퍼플렉서티 440.38\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 47[s] | 퍼플렉서티 477.08\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 51[s] | 퍼플렉서티 456.39\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 54[s] | 퍼플렉서티 388.35\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 58[s] | 퍼플렉서티 343.36\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 62[s] | 퍼플렉서티 404.28\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 65[s] | 퍼플렉서티 407.90\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 69[s] | 퍼플렉서티 331.26\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 73[s] | 퍼플렉서티 354.04\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 76[s] | 퍼플렉서티 343.42\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 80[s] | 퍼플렉서티 332.93\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 84[s] | 퍼플렉서티 328.38\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 87[s] | 퍼플렉서티 310.60\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 91[s] | 퍼플렉서티 316.82\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 95[s] | 퍼플렉서티 302.51\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 98[s] | 퍼플렉서티 316.17\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 102[s] | 퍼플렉서티 291.16\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 105[s] | 퍼플렉서티 257.86\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 109[s] | 퍼플렉서티 335.37\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 113[s] | 퍼플렉서티 315.04\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 116[s] | 퍼플렉서티 282.72\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 120[s] | 퍼플렉서티 267.65\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 124[s] | 퍼플렉서티 226.96\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 128[s] | 퍼플렉서티 251.59\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 131[s] | 퍼플렉서티 259.79\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 135[s] | 퍼플렉서티 222.67\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 138[s] | 퍼플렉서티 232.45\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 143[s] | 퍼플렉서티 219.79\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 146[s] | 퍼플렉서티 242.59\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 150[s] | 퍼플렉서티 225.25\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 154[s] | 퍼플렉서티 227.58\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 158[s] | 퍼플렉서티 221.80\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 161[s] | 퍼플렉서티 206.95\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 165[s] | 퍼플렉서티 253.63\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 169[s] | 퍼플렉서티 227.96\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 173[s] | 퍼플렉서티 231.14\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 176[s] | 퍼플렉서티 243.47\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 180[s] | 퍼플렉서티 229.89\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 184[s] | 퍼플렉서티 194.29\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 188[s] | 퍼플렉서티 224.50\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 191[s] | 퍼플렉서티 207.55\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 195[s] | 퍼플렉서티 197.58\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 199[s] | 퍼플렉서티 168.53\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 203[s] | 퍼플렉서티 192.88\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 206[s] | 퍼플렉서티 227.42\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 210[s] | 퍼플렉서티 207.86\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 214[s] | 퍼플렉서티 196.01\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 220[s] | 퍼플렉서티 190.53\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 224[s] | 퍼플렉서티 162.16\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 228[s] | 퍼플렉서티 159.74\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 232[s] | 퍼플렉서티 186.68\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 236[s] | 퍼플렉서티 171.49\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 240[s] | 퍼플렉서티 177.54\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 245[s] | 퍼플렉서티 222.77\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 248[s] | 퍼플렉서티 210.25\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 250[s] | 퍼플렉서티 223.35\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 253[s] | 퍼플렉서티 204.44\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 257[s] | 퍼플렉서티 188.76\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 262[s] | 퍼플렉서티 176.38\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 266[s] | 퍼플렉서티 159.51\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 270[s] | 퍼플렉서티 152.07\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 274[s] | 퍼플렉서티 161.33\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 277[s] | 퍼플렉서티 177.09\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 281[s] | 퍼플렉서티 192.55\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 284[s] | 퍼플렉서티 200.21\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 288[s] | 퍼플렉서티 184.11\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 292[s] | 퍼플렉서티 182.27\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 295[s] | 퍼플렉서티 175.80\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 299[s] | 퍼플렉서티 186.11\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 303[s] | 퍼플렉서티 184.30\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 307[s] | 퍼플렉서티 166.42\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 310[s] | 퍼플렉서티 137.12\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 314[s] | 퍼플렉서티 172.46\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 318[s] | 퍼플렉서티 197.66\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 322[s] | 퍼플렉서티 152.51\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 325[s] | 퍼플렉서티 168.04\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 329[s] | 퍼플렉서티 154.66\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 333[s] | 퍼플렉서티 161.85\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 336[s] | 퍼플렉서티 156.74\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 340[s] | 퍼플렉서티 156.10\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 344[s] | 퍼플렉서티 170.32\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 348[s] | 퍼플렉서티 172.33\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 352[s] | 퍼플렉서티 175.05\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 356[s] | 퍼플렉서티 153.14\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 360[s] | 퍼플렉서티 138.34\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 363[s] | 퍼플렉서티 191.89\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 367[s] | 퍼플렉서티 181.96\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 371[s] | 퍼플렉서티 165.06\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 374[s] | 퍼플렉서티 154.03\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 378[s] | 퍼플렉서티 128.22\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 382[s] | 퍼플렉서티 149.98\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 386[s] | 퍼플렉서티 160.03\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 389[s] | 퍼플렉서티 132.99\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 393[s] | 퍼플렉서티 131.79\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 397[s] | 퍼플렉서티 134.74\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 401[s] | 퍼플렉서티 147.65\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 405[s] | 퍼플렉서티 143.33\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 409[s] | 퍼플렉서티 144.93\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 412[s] | 퍼플렉서티 144.99\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 416[s] | 퍼플렉서티 130.53\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 420[s] | 퍼플렉서티 167.35\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 424[s] | 퍼플렉서티 147.24\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 428[s] | 퍼플렉서티 152.49\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 431[s] | 퍼플렉서티 162.59\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 435[s] | 퍼플렉서티 152.29\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 438[s] | 퍼플렉서티 131.78\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 442[s] | 퍼플렉서티 156.05\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 446[s] | 퍼플렉서티 143.39\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 450[s] | 퍼플렉서티 128.54\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 453[s] | 퍼플렉서티 110.77\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 457[s] | 퍼플렉서티 122.59\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 461[s] | 퍼플렉서티 153.87\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 464[s] | 퍼플렉서티 140.34\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 468[s] | 퍼플렉서티 132.08\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 472[s] | 퍼플렉서티 133.39\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 476[s] | 퍼플렉서티 111.46\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 479[s] | 퍼플렉서티 108.71\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 483[s] | 퍼플렉서티 129.56\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 487[s] | 퍼플렉서티 123.38\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 490[s] | 퍼플렉서티 123.02\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 495[s] | 퍼플렉서티 157.19\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 498[s] | 퍼플렉서티 152.38\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 500[s] | 퍼플렉서티 160.52\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 504[s] | 퍼플렉서티 144.26\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 507[s] | 퍼플렉서티 135.14\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 511[s] | 퍼플렉서티 128.35\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 514[s] | 퍼플렉서티 118.10\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 518[s] | 퍼플렉서티 105.44\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 522[s] | 퍼플렉서티 115.72\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 525[s] | 퍼플렉서티 125.23\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 529[s] | 퍼플렉서티 141.36\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 533[s] | 퍼플렉서티 150.41\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 536[s] | 퍼플렉서티 141.37\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 540[s] | 퍼플렉서티 140.07\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 544[s] | 퍼플렉서티 134.63\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 547[s] | 퍼플렉서티 138.79\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 551[s] | 퍼플렉서티 142.20\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 554[s] | 퍼플렉서티 123.71\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 558[s] | 퍼플렉서티 101.19\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 562[s] | 퍼플렉서티 124.08\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 566[s] | 퍼플렉서티 151.32\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 569[s] | 퍼플렉서티 114.97\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 573[s] | 퍼플렉서티 129.65\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 576[s] | 퍼플렉서티 113.30\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 580[s] | 퍼플렉서티 122.91\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 584[s] | 퍼플렉서티 117.07\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 587[s] | 퍼플렉서티 119.82\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 591[s] | 퍼플렉서티 129.18\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 595[s] | 퍼플렉서티 137.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 3 |  반복 541 / 1327 | 시간 598[s] | 퍼플렉서티 136.12\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 602[s] | 퍼플렉서티 118.76\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 606[s] | 퍼플렉서티 105.17\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 609[s] | 퍼플렉서티 149.08\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 613[s] | 퍼플렉서티 142.77\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 616[s] | 퍼플렉서티 128.77\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 620[s] | 퍼플렉서티 119.58\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 624[s] | 퍼플렉서티 99.04\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 628[s] | 퍼플렉서티 118.23\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 631[s] | 퍼플렉서티 126.12\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 635[s] | 퍼플렉서티 107.47\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 639[s] | 퍼플렉서티 103.90\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 642[s] | 퍼플렉서티 104.45\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 646[s] | 퍼플렉서티 115.90\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 650[s] | 퍼플렉서티 116.11\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 654[s] | 퍼플렉서티 115.09\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 658[s] | 퍼플렉서티 119.44\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 661[s] | 퍼플렉서티 105.59\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 665[s] | 퍼플렉서티 131.59\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 669[s] | 퍼플렉서티 118.33\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 672[s] | 퍼플렉서티 126.12\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 676[s] | 퍼플렉서티 131.27\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 680[s] | 퍼플렉서티 122.38\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 683[s] | 퍼플렉서티 108.11\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 687[s] | 퍼플렉서티 127.86\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 691[s] | 퍼플렉서티 119.26\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 694[s] | 퍼플렉서티 102.37\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 698[s] | 퍼플렉서티 88.30\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 702[s] | 퍼플렉서티 96.39\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 705[s] | 퍼플렉서티 121.67\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 709[s] | 퍼플렉서티 114.05\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 713[s] | 퍼플렉서티 104.66\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 716[s] | 퍼플렉서티 110.35\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 720[s] | 퍼플렉서티 92.64\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 724[s] | 퍼플렉서티 88.26\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 729[s] | 퍼플렉서티 104.86\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 734[s] | 퍼플렉서티 104.49\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 738[s] | 퍼플렉서티 100.38\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 743[s] | 퍼플렉서티 128.88\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 748[s] | 퍼플렉서티 125.84\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 749[s] | 퍼플렉서티 134.44\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 753[s] | 퍼플렉서티 121.38\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 757[s] | 퍼플렉서티 107.13\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 761[s] | 퍼플렉서티 107.29\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 765[s] | 퍼플렉서티 95.58\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 769[s] | 퍼플렉서티 86.21\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 773[s] | 퍼플렉서티 95.33\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 776[s] | 퍼플렉서티 102.21\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 780[s] | 퍼플렉서티 115.58\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 784[s] | 퍼플렉서티 128.03\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 788[s] | 퍼플렉서티 119.97\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 792[s] | 퍼플렉서티 120.53\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 796[s] | 퍼플렉서티 114.12\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 800[s] | 퍼플렉서티 113.89\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 804[s] | 퍼플렉서티 121.46\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 808[s] | 퍼플렉서티 103.96\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 813[s] | 퍼플렉서티 85.00\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 818[s] | 퍼플렉서티 100.04\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 822[s] | 퍼플렉서티 127.70\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 826[s] | 퍼플렉서티 97.30\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 831[s] | 퍼플렉서티 110.22\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 835[s] | 퍼플렉서티 93.84\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 839[s] | 퍼플렉서티 102.36\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 844[s] | 퍼플렉서티 99.24\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 848[s] | 퍼플렉서티 102.03\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 853[s] | 퍼플렉서티 108.06\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 856[s] | 퍼플렉서티 116.66\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 860[s] | 퍼플렉서티 113.04\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 863[s] | 퍼플렉서티 102.30\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 867[s] | 퍼플렉서티 88.81\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 871[s] | 퍼플렉서티 126.53\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 874[s] | 퍼플렉서티 121.23\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 878[s] | 퍼플렉서티 109.56\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 882[s] | 퍼플렉서티 102.04\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 885[s] | 퍼플렉서티 83.54\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 889[s] | 퍼플렉서티 101.99\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 893[s] | 퍼플렉서티 107.33\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 896[s] | 퍼플렉서티 94.08\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 900[s] | 퍼플렉서티 88.81\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 903[s] | 퍼플렉서티 87.90\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 907[s] | 퍼플렉서티 99.31\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 911[s] | 퍼플렉서티 101.77\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 914[s] | 퍼플렉서티 98.08\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 918[s] | 퍼플렉서티 104.23\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 922[s] | 퍼플렉서티 90.82\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 925[s] | 퍼플렉서티 115.68\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 929[s] | 퍼플렉서티 103.24\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 933[s] | 퍼플렉서티 111.44\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 937[s] | 퍼플렉서티 111.78\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 940[s] | 퍼플렉서티 106.24\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 944[s] | 퍼플렉서티 96.94\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 948[s] | 퍼플렉서티 111.40\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 952[s] | 퍼플렉서티 103.56\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 956[s] | 퍼플렉서티 88.79\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 961[s] | 퍼플렉서티 77.77\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 965[s] | 퍼플렉서티 80.72\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 969[s] | 퍼플렉서티 103.50\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 973[s] | 퍼플렉서티 99.15\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 978[s] | 퍼플렉서티 91.32\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 982[s] | 퍼플렉서티 94.58\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 986[s] | 퍼플렉서티 82.95\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 989[s] | 퍼플렉서티 74.76\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 993[s] | 퍼플렉서티 91.59\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 997[s] | 퍼플렉서티 92.92\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1000[s] | 퍼플렉서티 89.31\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1004[s] | 퍼플렉서티 110.34\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1008[s] | 퍼플렉서티 109.49\n",
      "Figure(640x480)\n",
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  136.37517985151163\n"
     ]
    }
   ],
   "source": [
    "!python train_rnnlm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862bb86",
   "metadata": {},
   "source": [
    "## 3. LSTM을 적용한 RNN Language Model\n",
    "\n",
    "앞 장에서 했던 SimpleRnnlm 과 다른 점은 단지 RNN 대신 LSTM을 사용했다는 것 뿐이다.\n",
    "(구현은 rnnlm.py, train_rnnlm.py 참고)\n",
    "(결과는 위 블록 참고)\n",
    "\n",
    "\n",
    "## 4. RNNLM 추가 개선\n",
    "\n",
    "### (1). LSTM 계층 다층화\n",
    "\n",
    "여러 개의 LSTM 계층을 쌓아서 모델 복잡도를 증가시키기. \n",
    "- 문제점 : 계층을 여러 개 쌓을 경우, 복잡도가 증가해 과대적합 문제가 발생할 여지가 있음.\n",
    "\n",
    "### (2). Dropout \n",
    "\n",
    "- LSTM 계층의 앞뒤에 Dropout 계층을 삽입하여 과대적합 문제를 억제하기.\n",
    "- 질문 1 : 정규화 (L2 or L1 Regularization)은 효과가 없나? -> Loss function에 대해 적용할 수 있기에 일단은 넘어가자.\n",
    "- 질문 2 : 시계열 방향의 Dropout은 안되나? : Variational Dropout 참고. (문헌 : https://arxiv.org/abs/1512.05287 )\n",
    "\n",
    "### (3). 가중치 공유 (weight tying)\n",
    "\n",
    "- Embedding 계층과 Affine 계층의 weight matrix를 똑같이 설정하기. \n",
    "- Embedding의 $W_A$ 가 (V,H)라면, Affine 계층의 $W_B = W^{T}_A$는 (H,V)로 transpose 관계를 갖게끔 한다.\n",
    "- 직관적으로 보면, 학습할 파라미터의 갯수가 줄어드는 효과가 있고, 모델 복잡도가 감소하여 과적합 방지에 좋을 것으로 예측됨.\n",
    "- 이게 효과가 있다는 이론적인 근거는 https://arxiv.org/abs/1611.01462 참고.\n",
    "\n",
    "### (4). 개선된 RNNLM 구현\n",
    "\n",
    "위의 개선점 3가지를 모두 적용한 BetterRnnlm 클래스 구현은 better_rnnlm.py 참고.\n",
    "- 구조 : input - Embedding - Dropout - LSTM - Dropout - LSTM - Dropout - Affine - SoftmaxWithLoss - Loss\n",
    "- Embedding 과 Affine이 가중치를 공유함.\n",
    "- 학습에 있어 Training set, Validation set, Test set으로 구분됨.\n",
    "- 훈련 과정의 퍼플렉서티 계산에는 Validation set이 사용됨.\n",
    "\n",
    "- 개선된 RNNLM : 퍼플렉서티 76.6 <- 기존 모델의 136.375보다 확실한 성능 향상!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6da88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
